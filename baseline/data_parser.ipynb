{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random, re\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from featurizer import LexicalFeaturizer\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/ICNALE_Written_Essays_2.3'\n",
    "merged_plain_dir = '{}/Merged/Plain Text'.format(data_dir)\n",
    "merged_tagged_dir = '{}/Merged/Tagged'.format(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_mapping = {\n",
    "    'A2_0': 4,\n",
    "    'B1_1': 3,\n",
    "    'B1_2': 2,\n",
    "    'B2_0': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_regex = re.compile(\"[/.!,?\\s]\")\n",
    "grammar_regex = re.compile(\"[,]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_merged_plain_v1():\n",
    "    script_length_dict = {} \n",
    "    \n",
    "    unigram_dict = Counter()\n",
    "    unigram_POS = Counter()\n",
    "\n",
    "    bigram_dict = Counter()\n",
    "    bigram_POS = Counter()    \n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    featurizer = LexicalFeaturizer()\n",
    "    \n",
    "    # Begins reading the merged plain file\n",
    "    for path in sorted(os.listdir(merged_plain_dir)):\n",
    "        file_name, file_ext = path.split('.')\n",
    "        attributes = file_name.split('_')\n",
    "\n",
    "        if len(attributes) == 4:\n",
    "            level = 0\n",
    "        else:\n",
    "            level = level_mapping['{}_{}'.format(attributes[3], attributes[4])]\n",
    "            \n",
    "        sample_counter = 0\n",
    "        sample_avg_words = 0\n",
    "        with open('{}/{}'.format(merged_plain_dir, path), 'r', encoding='utf-8-sig') as file:\n",
    "            for sample in file:\n",
    "                if sample == '\\n': continue\n",
    "                sample = sample.strip('\\n')\n",
    "                \n",
    "                sample_words = sample.split()\n",
    "                paragraph_len = len(sample_words)\n",
    "                sample_avg_words += paragraph_len\n",
    "                paragraph_gram_len = len(sample_words) + 1\n",
    "                for i in range(paragraph_len):\n",
    "                    cur_word = sample_words[i].lower()\n",
    "                    cur_word = [ w for w in punct_regex.split(cur_word) if w]\n",
    "                    if len(cur_word) <= 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        cur_word = cur_word[0]\n",
    "                    unigram_dict[cur_word] += 1\n",
    "                    \n",
    "                    if i == 0:\n",
    "                        bigram = \"<s>\"\n",
    "                    else:\n",
    "                        bigram = sample_words[i - 1].lower()\n",
    "                    bigram += \" \" + cur_word\n",
    "                    bigram_dict[bigram] += 1\n",
    "                    if i == paragraph_len - 1:\n",
    "                        final_bigram = cur_word + \" </s>\"\n",
    "                        bigram_dict[final_bigram] += 1\n",
    "\n",
    "                script_length_dict[file_name+str(sample_counter)] = (paragraph_len, paragraph_gram_len)\n",
    "                sample_counter += 1\n",
    "\n",
    "        with open('{}/{}'.format(merged_plain_dir, path), 'r', encoding='utf-8-sig') as file:\n",
    "            for sample in file:\n",
    "                if sample == '\\n': continue\n",
    "                sample = sample.strip('\\n')\n",
    "\n",
    "                p_features = featurizer.featurize(sample)\n",
    "                word_features = []\n",
    "                sample_words = sample.split()\n",
    "                words = [ w for w in punct_regex.split(sample) if w]\n",
    "                paragraph_len = len(words)\n",
    "                most_common = Counter(words).most_common(200)\n",
    "                for i in range(paragraph_len):\n",
    "                    cur_word = words[i]\n",
    "                    count = unigram_dict[cur_word.lower()]\n",
    "                    if count != 0:\n",
    "                        word_features.append(count/100)\n",
    "                data.append(np.array(word_features[:150] + p_features)) #TODO: add avg_sent_len and number of sentence))\n",
    "                labels.append(level)\n",
    "    return data, labels\n",
    "data, labels = parse_merged_plain_v1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_label = {}\n",
    "for i in range(len(data)):\n",
    "    if labels[i] not in data_by_label:\n",
    "        data_by_label[labels[i]] = [data[i]]\n",
    "    else:\n",
    "        data_by_label[labels[i]].append(data[i])\n",
    "trimmed_data = []\n",
    "trimmed_labels = []\n",
    "for label in data_by_label:\n",
    "    trimmed_data.extend(data_by_label[label][:400])\n",
    "    trimmed_labels.extend([label for i in range(400)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            trimmed_data, trimmed_labels, test_size=0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6739 epochs took 42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   41.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logreg = LogisticRegression(solver=\"saga\", \n",
    "                         multi_class=\"multinomial\", \n",
    "                         max_iter=10000,\n",
    "                         verbose=1)\n",
    "clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "[[129  15  34  38  43]\n",
      " [ 10 221  11   4   6]\n",
      " [ 32  17 104  53  46]\n",
      " [ 29  12  34 140  43]\n",
      " [ 18  30  13  84 114]]\n",
      "F1: 0.5489325353996829\n",
      "VAL\n",
      "[[10  8 18 12 25]\n",
      " [ 6 30  9  3 10]\n",
      " [10  7 19 23 12]\n",
      " [ 6  5 12 21 13]\n",
      " [12  6  7 20 16]]\n",
      "F1: 0.3038135793734537\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN')\n",
    "y_pred_train = clf_logreg.predict(X_train)\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print('F1: {}'.format(f1_score(y_train, y_pred_train, average='macro')))\n",
    "print('VAL')\n",
    "y_pred = clf_logreg.predict(X_val)\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "[[45  1 12  5  5]\n",
      " [ 3 55 16 12  4]\n",
      " [13  6 34 19  5]\n",
      " [ 8  7 12 51  7]\n",
      " [ 5  2  6 10 57]]\n",
      "F1: 0.6064224394911235\n"
     ]
    }
   ],
   "source": [
    "print('TEST')\n",
    "y_pred = clf_dectree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('F1: {}'.format(f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dectree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "clf_dectree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "[[240   3  12   4   0]\n",
      " [  4 234   9   4   1]\n",
      " [ 10   3 229  10   0]\n",
      " [ 14  10  10 223   1]\n",
      " [  6   4   7  10 232]]\n",
      "F1: 0.9050669374580924\n",
      "VAL\n",
      "[[40  7 18  7  1]\n",
      " [ 5 36 12  3  2]\n",
      " [10  7 32 15  7]\n",
      " [ 4  4 12 35  2]\n",
      " [ 5  1  5  6 44]]\n",
      "F1: 0.5938037714585331\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN')\n",
    "y_pred_train = clf_dectree.predict(X_train)\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print('F1: {}'.format(f1_score(y_train, y_pred_train, average='macro')))\n",
    "print('VAL')\n",
    "y_pred = clf_dectree.predict(X_val)\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "[[45  1 12  5  5]\n",
      " [ 3 55 16 12  4]\n",
      " [13  6 34 19  5]\n",
      " [ 8  7 12 51  7]\n",
      " [ 5  2  6 10 57]]\n",
      "F1: 0.6064224394911235\n"
     ]
    }
   ],
   "source": [
    "print('TEST')\n",
    "y_pred = clf_dectree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('F1: {}'.format(f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
