{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Concatenate, Reshape, LSTM, Dense, Dropout\n",
    "from keras.utils import multi_gpu_model, Sequence\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sys.path.append(os.path.abspath('../preprocessing/'))\n",
    "from data_parser import DataParser\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_data [[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "shuffle [[0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "balance [[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "shuffle [[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "dp = DataParser(Config.embed_dim, Config.max_seq_len)\n",
    "sequences, labels, embed_matrix = dp.load_data()\n",
    "print 'parse_data', labels[:400]\n",
    "\n",
    "sequences, labels = dp.shuffle_data(sequences, labels)\n",
    "print 'shuffle', labels[:400]\n",
    "\n",
    "x_train_seq, y_train = dp.balance_labels(sequences, labels)\n",
    "print 'balance', y_train[:400]\n",
    "\n",
    "x_train_seq, y_train = dp.shuffle_data(x_train_seq, y_train)\n",
    "print 'shuffle', y_train[:400]\n",
    "\n",
    "x_train_syn = np.random.randint(0, high=10, size=(int(x_train_seq.shape[0]), int( x_train_seq.shape[1])))\n",
    "x_train_lex = np.random.rand(int(x_train_seq.shape[0]), Config.lex_feats,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_input (InputLayer)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 200, 50)           808750    \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 10)                2440      \n",
      "_________________________________________________________________\n",
      "dense_layer_0 (Dense)        (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_layer_1 (Dense)        (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 811,335\n",
      "Trainable params: 2,585\n",
      "Non-trainable params: 808,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_input = Input(shape=(Config.max_seq_len,), dtype='int32', name='seq_input')\n",
    "syn_input = Input(shape=(Config.max_seq_len,), dtype='float32', name='syn_input')\n",
    "lex_input = Input(shape=(Config.lex_feats,), dtype='float32', name='lex_input')\n",
    "\n",
    "seq_embeds = Embedding(embed_matrix.shape[0], Config.embed_dim, \n",
    "                       weights=[embed_matrix], input_length=Config.max_seq_len,\n",
    "                       trainable=False,\n",
    "                       embeddings_regularizer=keras.regularizers.l2(.01),\n",
    "                       name='embedding_layer')(seq_input)\n",
    "\n",
    "syn_addons = Reshape((Config.max_seq_len, 1), name='reshape_layer')(syn_input)\n",
    "\n",
    "time_series = seq_embeds\n",
    "# time_series = Concatenate()([seq_embeds, syn_addons])\n",
    "\n",
    "lstm_output = LSTM(Config.lstm_units, \n",
    "                   activation='relu',\n",
    "                   name='lstm_layer')(time_series)\n",
    "\n",
    "# concat = Concatenate()([lstm_output, lex_input])\n",
    "concat = lstm_output\n",
    "\n",
    "feed = concat\n",
    "for i in range(3):\n",
    "    feed = Dense(Config.lstm_units // 2,\n",
    "                 activation='relu',\n",
    "                 name='dense_layer_{}'.format(i))(feed)\n",
    "#     feed = Dropout(.01)(feed)\n",
    "\n",
    "predictions = Dense(Config.num_classes,\n",
    "                    activation='softmax',\n",
    "                    name='predictions')(feed)\n",
    "\n",
    "model = Model(inputs=[seq_input, syn_input, lex_input], outputs=predictions)\n",
    "\n",
    "sgd = optimizers.SGD(lr=Config.learning_rate, decay=Config.learning_decay)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3081.2282 - acc: 0.2033 - val_loss: 3081.2239 - val_acc: 0.1880\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2227 - acc: 0.2033 - val_loss: 3081.2225 - val_acc: 0.1880\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2220 - acc: 0.2040 - val_loss: 3081.2220 - val_acc: 0.1980\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2215 - acc: 0.2153 - val_loss: 3081.2216 - val_acc: 0.2120\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2214 - acc: 0.2187 - val_loss: 3081.2218 - val_acc: 0.2380\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2212 - acc: 0.2220 - val_loss: 3081.2216 - val_acc: 0.2400\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2212 - acc: 0.2087 - val_loss: 3081.2219 - val_acc: 0.2260\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2210 - acc: 0.2287 - val_loss: 3081.2217 - val_acc: 0.2240\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2208 - acc: 0.2240 - val_loss: 3081.2219 - val_acc: 0.2200\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2208 - acc: 0.2333 - val_loss: 3081.2219 - val_acc: 0.2180\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2204 - acc: 0.2120 - val_loss: 3081.2213 - val_acc: 0.2080\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2205 - acc: 0.2187 - val_loss: 3081.2213 - val_acc: 0.2060\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2203 - acc: 0.2373 - val_loss: 3081.2219 - val_acc: 0.2040\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2201 - acc: 0.2213 - val_loss: 3081.2221 - val_acc: 0.2080\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2196 - acc: 0.2340 - val_loss: 3081.2218 - val_acc: 0.2100\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2197 - acc: 0.2247 - val_loss: 3081.2214 - val_acc: 0.2080\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2195 - acc: 0.2147 - val_loss: 3081.2215 - val_acc: 0.2060\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3081.2192 - acc: 0.2200 - val_loss: 3081.2221 - val_acc: 0.2140\n",
      "Epoch 19/50\n",
      " 352/1500 [======>.......................] - ETA: 8s - loss: 3081.2194 - acc: 0.2415"
     ]
    }
   ],
   "source": [
    "model.fit([x_train_seq, x_train_syn, x_train_lex], y_train, \n",
    "          batch_size=Config.batch_size, \n",
    "          epochs=Config.epochs, \n",
    "          validation_split=0.25)\n",
    "\n",
    "y_pred_test = model.predict_on_batch([x_train_seq, x_train_syn, x_train_lex])\n",
    "print confusion_matrix(y_train.argmax(axis=-1), y_pred_test.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
